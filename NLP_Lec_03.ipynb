{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T17:56:06.205377Z",
     "iopub.status.busy": "2023-11-12T17:56:06.204965Z",
     "iopub.status.idle": "2023-11-12T17:56:06.237262Z",
     "shell.execute_reply": "2023-11-12T17:56:06.235921Z",
     "shell.execute_reply.started": "2023-11-12T17:56:06.205343Z"
    }
   },
   "source": [
    "## **NLP Lecture -03:** **Text Preprocessing**\n",
    "- LINK: https://www.nltk.org/nltk_data/  \n",
    "## **Contents:**\n",
    "\n",
    "- **[a. Removing HTML Tags](#a.-Removing-HTML-Tags)**\n",
    "- **[b. Lower/Upper Case](#b.-Lower/Upper-Case)**\n",
    "- **[c. Removing URLs](#c.-Removing-URLs)**\n",
    "- **[d. Removing Punctuation](#d.-Removing-Punctuation)**  \n",
    "- **[e. Chat Word Treatment](#e.-Chat-Word-Treatment)**\n",
    "- **[f. Spelling Correction](#f.-Spelling-Correction)**\n",
    "- **[g. Removing Stop Words](#g.-Removing-Stop-Words)**\n",
    "- **[h. Handling Emojis](#h.-Handling-Emojis)**\n",
    "- **[i. Tokenization](#i.-Tokenization)**\n",
    "- **[j. Stemming](#j.-Stemming)**\n",
    "- **[k. Lemmatization](#k.-Lemmatization)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment_03\n",
    "- **API LINK:**  \n",
    "- https://api.themoviedb.org/3/movie/top_rated?api_key=8265bd1679663a7ea12ac168da84d2e8&language=en-US&page=471\n",
    "- https://api.themoviedb.org/3/genre/movie/list?api_key=8265bd1679663a7ea12ac168da84d2e8&language=en-US\n",
    "\n",
    "# Steps:\n",
    "- Create the dataset and perform preprocessing\n",
    "- Dataset will be multi-class classification (movie_name, description, genre)\n",
    "- Use TMDB API website/ Given link\n",
    "- Extract the data and store it in dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-11-13T11:43:16.020586Z",
     "iopub.status.busy": "2023-11-13T11:43:16.019874Z",
     "iopub.status.idle": "2023-11-13T11:43:16.475203Z",
     "shell.execute_reply": "2023-11-13T11:43:16.473849Z",
     "shell.execute_reply.started": "2023-11-13T11:43:16.020538Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importing Library\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "# Creating connection with dataset\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T11:43:21.068230Z",
     "iopub.status.busy": "2023-11-13T11:43:21.066826Z",
     "iopub.status.idle": "2023-11-13T11:43:22.741312Z",
     "shell.execute_reply": "2023-11-13T11:43:22.740183Z",
     "shell.execute_reply.started": "2023-11-13T11:43:21.068174Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reading the dataset\n",
    "df = pd.read_csv('/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T08:05:05.651759Z",
     "iopub.status.busy": "2023-11-13T08:05:05.651327Z",
     "iopub.status.idle": "2023-11-13T08:05:05.661759Z",
     "shell.execute_reply": "2023-11-13T08:05:05.660553Z",
     "shell.execute_reply.started": "2023-11-13T08:05:05.651728Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 2), 100000)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape and size of dataset\n",
    "df.shape, df.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **a. Removing HTML Tags**\n",
    "- HTML tags are used for representation on web browser\n",
    "- Remove all HTML tags because we don't require in NLP\n",
    "- Require to remove almost every time specially for scrapped data from websites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T11:44:05.769630Z",
     "iopub.status.busy": "2023-11-13T11:44:05.768538Z",
     "iopub.status.idle": "2023-11-13T11:44:05.775655Z",
     "shell.execute_reply": "2023-11-13T11:44:05.774409Z",
     "shell.execute_reply.started": "2023-11-13T11:44:05.769581Z"
    }
   },
   "outputs": [],
   "source": [
    "# Defining function\n",
    "import re\n",
    "def remove_html_tags(text):\n",
    "    p = re.compile(r'<.*?>')\n",
    "    return p.sub('', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T04:19:49.131583Z",
     "iopub.status.busy": "2023-11-13T04:19:49.131135Z",
     "iopub.status.idle": "2023-11-13T04:19:49.139585Z",
     "shell.execute_reply": "2023-11-13T04:19:49.138195Z",
     "shell.execute_reply.started": "2023-11-13T04:19:49.131551Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<html> <head> <style> </style> </head> <body> <p>Lorem ipsum dolor sit amet,<a href= http://google.com> consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. </p> </body> </html>'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample1 = '<html> <head> <style> </style> </head> <body> <p>Lorem ipsum dolor sit amet,<a href= http://google.com> consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. </p> </body> </html>'\n",
    "sample1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T04:20:17.678678Z",
     "iopub.status.busy": "2023-11-13T04:20:17.678203Z",
     "iopub.status.idle": "2023-11-13T04:20:17.686242Z",
     "shell.execute_reply": "2023-11-13T04:20:17.684997Z",
     "shell.execute_reply.started": "2023-11-13T04:20:17.678639Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'      Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.   '"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_html_tags(sample1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T11:45:09.639272Z",
     "iopub.status.busy": "2023-11-13T11:45:09.638201Z",
     "iopub.status.idle": "2023-11-13T11:45:09.771896Z",
     "shell.execute_reply": "2023-11-13T11:45:09.770831Z",
     "shell.execute_reply.started": "2023-11-13T11:45:09.639223Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. The filming tec...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. The filming tec...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying on dataset\n",
    "df['review'] = df['review'].apply(lambda x: remove_html_tags(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **b. Lower/Upper case**\n",
    "- Convert text to lower/upper case\n",
    "- Require to do almost every time\n",
    "- To make meaning of words in different cases same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T04:20:48.781263Z",
     "iopub.status.busy": "2023-11-13T04:20:48.780818Z",
     "iopub.status.idle": "2023-11-13T04:20:48.788972Z",
     "shell.execute_reply": "2023-11-13T04:20:48.787817Z",
     "shell.execute_reply.started": "2023-11-13T04:20:48.781230Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet & his parents are fighting all the time.This movie is slower than a soap opera... and suddenly, Jake decides to become Rambo and kill the zombie.OK, first of all when you're going to make a film you must Decide if its a thriller or a drama! As a drama the movie is watchable. Parents are divorcing & arguing like in real life. And then we have Jake with his closet which totally ruins all the film! I expected to see a BOOGEYMAN similar movie, and instead i watched a drama with some meaningless thriller spots.3 out of 10 just for the well playing parents & descent dialogs. As for the shots with Jake: just ignore them.\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample2 = df['review'][3]\n",
    "sample2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T04:22:18.869267Z",
     "iopub.status.busy": "2023-11-13T04:22:18.868275Z",
     "iopub.status.idle": "2023-11-13T04:22:18.877076Z",
     "shell.execute_reply": "2023-11-13T04:22:18.875729Z",
     "shell.execute_reply.started": "2023-11-13T04:22:18.869206Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"basically there's a family where a little boy (jake) thinks there's a zombie in his closet & his parents are fighting all the time.this movie is slower than a soap opera... and suddenly, jake decides to become rambo and kill the zombie.ok, first of all when you're going to make a film you must decide if its a thriller or a drama! as a drama the movie is watchable. parents are divorcing & arguing like in real life. and then we have jake with his closet which totally ruins all the film! i expected to see a boogeyman similar movie, and instead i watched a drama with some meaningless thriller spots.3 out of 10 just for the well playing parents & descent dialogs. as for the shots with jake: just ignore them.\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample2.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T11:46:05.577544Z",
     "iopub.status.busy": "2023-11-13T11:46:05.576356Z",
     "iopub.status.idle": "2023-11-13T11:46:05.808674Z",
     "shell.execute_reply": "2023-11-13T11:46:05.807533Z",
     "shell.execute_reply.started": "2023-11-13T11:46:05.577496Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production. the filming tec...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei's \"love in the time of money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  one of the other reviewers has mentioned that ...  positive\n",
       "1  a wonderful little production. the filming tec...  positive\n",
       "2  i thought this was a wonderful way to spend ti...  positive\n",
       "3  basically there's a family where a little boy ...  negative\n",
       "4  petter mattei's \"love in the time of money\" is...  positive"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying on dataset\n",
    "df['review'] = df['review'].str.lower()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **c. Removing URLs**\n",
    "- Remove all the URLs from the text\n",
    "- Required when dealing with the data of social media platform\n",
    "- Removing URLs will be beneficial because it will ensures to get rid of ambiguity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T04:28:41.506594Z",
     "iopub.status.busy": "2023-11-13T04:28:41.506141Z",
     "iopub.status.idle": "2023-11-13T04:28:41.512600Z",
     "shell.execute_reply": "2023-11-13T04:28:41.511453Z",
     "shell.execute_reply.started": "2023-11-13T04:28:41.506557Z"
    }
   },
   "outputs": [],
   "source": [
    "# Defining function\n",
    "import re\n",
    "def remove_urls(text):\n",
    "    p = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return p.sub('', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T04:28:49.244842Z",
     "iopub.status.busy": "2023-11-13T04:28:49.244005Z",
     "iopub.status.idle": "2023-11-13T04:28:49.252034Z",
     "shell.execute_reply": "2023-11-13T04:28:49.250810Z",
     "shell.execute_reply.started": "2023-11-13T04:28:49.244801Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Check my notebook on https://www.kaggle.com/campusx/notebook01 or on http://www.kaggle.com/campusx/notebook01 else www.google.com/mynotebook01'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample3='Check my notebook on https://www.kaggle.com/campusx/notebook01 or on http://www.kaggle.com/campusx/notebook01 else www.google.com/mynotebook01'\n",
    "sample3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T04:29:04.940023Z",
     "iopub.status.busy": "2023-11-13T04:29:04.939453Z",
     "iopub.status.idle": "2023-11-13T04:29:04.946603Z",
     "shell.execute_reply": "2023-11-13T04:29:04.945597Z",
     "shell.execute_reply.started": "2023-11-13T04:29:04.939940Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Check my notebook on  or on  else '"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_urls(sample3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T04:29:14.660090Z",
     "iopub.status.busy": "2023-11-13T04:29:14.659236Z",
     "iopub.status.idle": "2023-11-13T04:29:16.664380Z",
     "shell.execute_reply": "2023-11-13T04:29:16.663247Z",
     "shell.execute_reply.started": "2023-11-13T04:29:14.660049Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production. the filming tec...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei's \"love in the time of money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  one of the other reviewers has mentioned that ...  positive\n",
       "1  a wonderful little production. the filming tec...  positive\n",
       "2  i thought this was a wonderful way to spend ti...  positive\n",
       "3  basically there's a family where a little boy ...  negative\n",
       "4  petter mattei's \"love in the time of money\" is...  positive"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying on dataset\n",
    "df['review'] = df['review'].apply(lambda x: remove_urls(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **d. Removing Punctuation**\n",
    "- Remove all unnecessary special characters\n",
    "- Removing punctuation will make the data more consistent for further processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method-01:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T11:49:37.229091Z",
     "iopub.status.busy": "2023-11-13T11:49:37.228353Z",
     "iopub.status.idle": "2023-11-13T11:49:37.236073Z",
     "shell.execute_reply": "2023-11-13T11:49:37.234720Z",
     "shell.execute_reply.started": "2023-11-13T11:49:37.229048Z"
    }
   },
   "outputs": [],
   "source": [
    "# Method-01: Defining function\n",
    "import re\n",
    "\n",
    "def remove_spchar(text):\n",
    "    p = r'[^a-zA-Z0-9\\s]'             # This pattern will keep letters, digits, and whitespaces\n",
    "    results = re.sub(p, '', text)     # sub() function to replace matches with an empty string\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T11:49:42.818273Z",
     "iopub.status.busy": "2023-11-13T11:49:42.817848Z",
     "iopub.status.idle": "2023-11-13T11:49:42.826294Z",
     "shell.execute_reply": "2023-11-13T11:49:42.824843Z",
     "shell.execute_reply.started": "2023-11-13T11:49:42.818238Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello How are you Is it fine Lets meet tomorrow \n",
      "68.27116012573242\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start =time.time()\n",
    "sample4 = \"Hello!, How are you? Is it -->fine!!!, Let's meet tomorrow @->:)\"\n",
    "print(remove_spchar(sample4))\n",
    "end=time.time()\n",
    "print((end-start)*50000)   # time would take for 50K records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method-02:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T11:49:57.988546Z",
     "iopub.status.busy": "2023-11-13T11:49:57.988129Z",
     "iopub.status.idle": "2023-11-13T11:49:57.997106Z",
     "shell.execute_reply": "2023-11-13T11:49:57.995718Z",
     "shell.execute_reply.started": "2023-11-13T11:49:57.988515Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting all punctuation\n",
    "import string\n",
    "spchar = string.punctuation\n",
    "spchar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T11:51:03.488803Z",
     "iopub.status.busy": "2023-11-13T11:51:03.487889Z",
     "iopub.status.idle": "2023-11-13T11:51:03.494391Z",
     "shell.execute_reply": "2023-11-13T11:51:03.493225Z",
     "shell.execute_reply.started": "2023-11-13T11:51:03.488763Z"
    }
   },
   "outputs": [],
   "source": [
    "# Method-02: Defining function                                     ---More Useful---\n",
    "\n",
    "spchar = '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'\n",
    "def remove_spchar1(text):\n",
    "    for char in spchar:\n",
    "        text = text.replace(char, '')\n",
    "    return text\n",
    "\n",
    "# If above function not works --> Datatype issue\n",
    "def remove_spchar1(text):\n",
    "    if isinstance(text, str):\n",
    "        for char in spchar:\n",
    "            text = text.replace(char, '')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T11:51:07.968815Z",
     "iopub.status.busy": "2023-11-13T11:51:07.967639Z",
     "iopub.status.idle": "2023-11-13T11:51:07.975441Z",
     "shell.execute_reply": "2023-11-13T11:51:07.974115Z",
     "shell.execute_reply.started": "2023-11-13T11:51:07.968773Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello How are you Is it fine Lets meet tomorrow \n",
      "11.289119720458984\n"
     ]
    }
   ],
   "source": [
    "start =time.time()\n",
    "sample4 = \"Hello!, How are you? Is it -->fine!!!, Let's meet tomorrow @->:)\"\n",
    "print(remove_spchar1(sample4))\n",
    "end=time.time()\n",
    "print((end-start)*50000)   # time would take for 50K records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method-03:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T11:51:23.048542Z",
     "iopub.status.busy": "2023-11-13T11:51:23.048147Z",
     "iopub.status.idle": "2023-11-13T11:51:23.054651Z",
     "shell.execute_reply": "2023-11-13T11:51:23.053152Z",
     "shell.execute_reply.started": "2023-11-13T11:51:23.048510Z"
    }
   },
   "outputs": [],
   "source": [
    "# Method-03: Defining function\n",
    "\n",
    "spchar = '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'\n",
    "def remove_spchar2(text):\n",
    "    return text.translate(str.maketrans('', '', spchar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T11:51:34.956937Z",
     "iopub.status.busy": "2023-11-13T11:51:34.956039Z",
     "iopub.status.idle": "2023-11-13T11:51:34.965741Z",
     "shell.execute_reply": "2023-11-13T11:51:34.964269Z",
     "shell.execute_reply.started": "2023-11-13T11:51:34.956887Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello How are you Is it fine Lets meet tomorrow \n",
      "68.73607635498047\n"
     ]
    }
   ],
   "source": [
    "start =time.time()\n",
    "sample4 = \"Hello!, How are you? Is it -->fine!!!, Let's meet tomorrow @->:)\"\n",
    "print(remove_spchar2(sample4))\n",
    "end=time.time()\n",
    "print((end-start)*50000)   # time would take for 50K records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T11:53:30.115029Z",
     "iopub.status.busy": "2023-11-13T11:53:30.114596Z",
     "iopub.status.idle": "2023-11-13T11:53:32.244264Z",
     "shell.execute_reply": "2023-11-13T11:53:32.243354Z",
     "shell.execute_reply.started": "2023-11-13T11:53:30.114978Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production the filming tech...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically theres a family where a little boy j...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter matteis love in the time of money is a ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  one of the other reviewers has mentioned that ...  positive\n",
       "1  a wonderful little production the filming tech...  positive\n",
       "2  i thought this was a wonderful way to spend ti...  positive\n",
       "3  basically theres a family where a little boy j...  negative\n",
       "4  petter matteis love in the time of money is a ...  positive"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying on dataset\n",
    "df['review'] = df['review'].apply(lambda x: remove_spchar1(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **e. Chat Word Treatment**\n",
    "- Make chat words in normal form\n",
    "- Required when working on such type of data which is based on social media/messaging app\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T11:53:56.303788Z",
     "iopub.status.busy": "2023-11-13T11:53:56.303405Z",
     "iopub.status.idle": "2023-11-13T11:53:56.336135Z",
     "shell.execute_reply": "2023-11-13T11:53:56.334647Z",
     "shell.execute_reply.started": "2023-11-13T11:53:56.303758Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chat words listed: 243\n"
     ]
    }
   ],
   "source": [
    "# Dictionary having set of chat words\n",
    "chat_word_dict = {'$': ' Dollar ',\n",
    " '4AO': 'For Adults Only',\n",
    " '7K': 'Sick:-D Laughter',\n",
    " 'A.M': 'Before Midday',\n",
    " 'A3': 'Anytime, Anywhere, Anyplace',\n",
    " 'AAMOF': 'As A Matter Of Fact',\n",
    " 'ACCT': 'Account',\n",
    " 'ADIH': 'Another Day In Hell',\n",
    " 'AFAIC': 'As Far As I Am Concerned',\n",
    " 'AFAICT': 'As Far As I Can Tell',\n",
    " 'AFAIK': 'As Far As I Know',\n",
    " 'AFAIR': 'As Far As I Remember',\n",
    " 'AFK': 'Away From Keyboard',\n",
    " 'APP': 'Application',\n",
    " 'APPROX': 'Approximately',\n",
    " 'APPS': 'Applications',\n",
    " 'ASAP': 'As Soon As Possible',\n",
    " 'ASL': 'Age, Sex, Location',\n",
    " 'ATK': 'At The Keyboard',\n",
    " 'ATM': 'At The Moment',\n",
    " 'AVE.': 'Avenue',\n",
    " 'AYMM': 'Are You My Mother',\n",
    " 'AYOR': 'At Your Own Risk',\n",
    " 'B&B': 'Bed And Breakfast',\n",
    " 'B+B': 'Bed And Breakfast',\n",
    " 'B.C': 'Before Christ',\n",
    " 'B2B': 'Business To Business',\n",
    " 'B2C': 'Business To Customer',\n",
    " 'B4': 'Before',\n",
    " 'B4N': 'Bye For Now',\n",
    " 'B@U': 'Back At You',\n",
    " 'BABE': 'Baby or Wife',\n",
    " 'BAE': 'Before Anyone Else',\n",
    " 'BAK': 'Back At Keyboard',\n",
    " 'BBBG': 'Bye Bye Be Good',\n",
    " 'BBC': 'British Broadcasting Corporation',\n",
    " 'BBIAS': 'Be Back In A Second',\n",
    " 'BBL': 'Be Back Later',\n",
    " 'BBS': 'Be Back Soon',\n",
    " 'BE4': 'Before',\n",
    " 'BFF': 'Best Friends Forever',\n",
    " 'BFN': 'Bye For Now',\n",
    " 'BLVD': 'Boulevard',\n",
    " 'BOUT': 'About',\n",
    " 'BRB': 'Be Right Back',\n",
    " 'BROS': 'Brothers',\n",
    " 'BRT': 'Be Right There',\n",
    " 'BSAAW': 'Big Smile And A Wink',\n",
    " 'BTW': 'By The Way',\n",
    " 'BWL': 'Bursting With Laughter',\n",
    " 'C/O': 'Care Of',\n",
    " 'CET': 'Central European Time',\n",
    " 'CF': 'Compare',\n",
    " 'CIA': 'Central Intelligence Agency',\n",
    " 'CSL': 'Can’T Stop Laughing',\n",
    " 'CU': 'See You',\n",
    " 'CUL8R': 'See You Later',\n",
    " 'CV': 'Curriculum Vitae',\n",
    " 'CWOT': 'Complete Waste Of Time',\n",
    " 'CYA': 'See You Again',\n",
    " 'CYL': 'See You Later',\n",
    " 'CYT': 'See You Tomorrow',\n",
    " 'DAE': 'Does Anyone Else',\n",
    " 'DBMIB': 'Do Not Bother Me I Am Busy',\n",
    " 'DIY': 'Do It Yourself',\n",
    " 'DM': 'Direct Message',\n",
    " 'DWH': 'During Work Hours',\n",
    " 'E123': 'Easy As One Two Three',\n",
    " 'EET': 'Eastern European Time',\n",
    " 'EG': 'Example',\n",
    " 'EMBM': 'Early Morning Business Meeting',\n",
    " 'ENCL': 'Enclosed',\n",
    " 'ENCL.': 'Enclosed',\n",
    " 'ETC': 'Et-cetera',\n",
    " 'FAQ': 'Frequently Asked Questions',\n",
    " 'FAWC': 'For Anyone Who Cares',\n",
    " 'FB': 'Facebook',\n",
    " 'FC': 'Fingers Crossed',\n",
    " 'FIG': 'Figure',\n",
    " 'FIMH': 'Forever In My Heart',\n",
    " 'FT': 'Featuring',\n",
    " 'FT.': 'Feet',\n",
    " 'FTL': 'For The Loss',\n",
    " 'FTW': 'For The Win',\n",
    " 'FWIW': \"For What It'S Worth\",\n",
    " 'FYI': 'For Your Information',\n",
    " 'G.O.A.T': 'Greatest Of All Time',\n",
    " 'G9': 'Genius',\n",
    " 'G9T': 'Good Night',\n",
    " 'GAHOY': 'Get A Hold Of Yourself',\n",
    " 'GAL': 'Get A Life',\n",
    " 'GCSE': 'General Certificate Of Secondary Education',\n",
    " 'GFN': 'Gone For Now',\n",
    " 'GG': 'Good Game',\n",
    " 'GL': 'Good Luck',\n",
    " 'GLHF': 'Good Luck Have Fun',\n",
    " 'GMT': 'Greenwich Mean Time',\n",
    " 'GMTA': 'Great Minds Think Alike',\n",
    " 'GN': 'Good Night',\n",
    " 'GNTCSD': 'Good Night Take Care Sweet Dream',\n",
    " 'GOAT': 'Greatest Of All Time',\n",
    " 'GOI': 'Get Over It',\n",
    " 'GPS': 'Global Positioning System',\n",
    " 'GR8': 'Great!',\n",
    " 'GRATZ': 'Congratulations',\n",
    " 'GYAL': 'Girl',\n",
    " 'H&C': 'Hot And Cold',\n",
    " 'HM': 'Yes',\n",
    " 'HMM': 'Yes',\n",
    " 'HP': 'Horsepower',\n",
    " 'HR': 'Hour',\n",
    " 'HRH': 'His Royal Highness',\n",
    " 'HT': 'Height',\n",
    " 'I.E': 'That Is',\n",
    " 'IBRB': 'I Will Be Right Back',\n",
    " 'IC': 'I See',\n",
    " 'ICQ': 'I Seek You (Also A Chat Program)',\n",
    " 'ICYMI': 'In Case You Missed It',\n",
    " 'IDC': 'I Don’t Care',\n",
    " 'IDGADF': 'I Do Not Give A Damn Fuck',\n",
    " 'IDGAF': 'I Do Not Give A Fuck',\n",
    " 'IDK': 'I Do Not Know',\n",
    " 'IE': 'That Is',\n",
    " 'IFYP': 'I Feel Your Pain',\n",
    " 'IG': 'Instagram',\n",
    " 'IIRC': 'If I Remember Correctly',\n",
    " 'ILU': 'I Love You',\n",
    " 'ILY': 'I Love You',\n",
    " 'IMHO': 'In My Honest/Humble Opinion',\n",
    " 'IMO': 'In My Opinion',\n",
    " 'IMU': 'I Miss You',\n",
    " 'IOW': 'In Other Words',\n",
    " 'IRL': 'In Real Life',\n",
    " 'J4F': 'Just For Fun',\n",
    " 'JIC': 'Just In Case',\n",
    " 'JK': 'Just Kidding',\n",
    " 'JSYK': 'Just So You Know',\n",
    " 'KISS': 'Keep It Simple, Stupid',\n",
    " 'L8R': 'Later',\n",
    " 'LB': 'Pound',\n",
    " 'LBS': 'Pounds',\n",
    " 'LDR': 'Long Distance Relationship',\n",
    " 'LMAO': 'Laughing My A** Off',\n",
    " 'LMFAO': 'Laugh My Fucking Ass Off',\n",
    " 'LOL': 'Laughing Out Loud',\n",
    " 'LTD': 'Limited',\n",
    " 'LTNS': 'Long Time No See',\n",
    " 'M8': 'Mate',\n",
    " 'MF': 'Motherfucker',\n",
    " 'MFS': 'Motherfuckers',\n",
    " 'MFW': 'My Face When',\n",
    " 'MOFO': 'Motherfucker',\n",
    " 'MPH': 'Miles Per Hour',\n",
    " 'MR': 'Mister',\n",
    " 'MRW': 'My Reaction When',\n",
    " 'MS': 'Miss',\n",
    " 'MTE': 'My Thoughts Exactly',\n",
    " 'NAGI': 'Not A Good Idea',\n",
    " 'NBC': 'National Broadcasting Company',\n",
    " 'NBD': 'Not Big Deal',\n",
    " 'NFS': 'Not For Sale',\n",
    " 'NGL': 'Not Going To Lie',\n",
    " 'NHS': 'National Health Service',\n",
    " 'NRN': 'No Reply Necessary',\n",
    " 'NSFL': 'Not Safe For Life',\n",
    " 'NSFW': 'Not Safe For Work',\n",
    " 'NTH': 'Nice To Have',\n",
    " 'NVR': 'Never',\n",
    " 'N8T': 'Night',\n",
    " 'NYC': 'New York City',\n",
    " 'OC': 'Original Content',\n",
    " 'OG': 'Original',\n",
    " 'OHP': 'Overhead Projector',\n",
    " 'OIC': 'Oh I See',\n",
    " 'OMDB': 'Over My Dead Body',\n",
    " 'OMG': 'Oh My God',\n",
    " 'OMW': 'On My Way',\n",
    " 'P.A': 'Per Annum',\n",
    " 'P.M': 'After Midday',\n",
    " 'PITA': 'Pain In The A..',\n",
    " 'PM': 'Prime Minister',\n",
    " 'POC': 'People Of Color',\n",
    " 'POV': 'Point Of View',\n",
    " 'PP': 'Pages',\n",
    " 'PPL': 'People',\n",
    " 'PRT': 'Party',\n",
    " 'PRW': 'Parents Are Watching',\n",
    " 'PS': 'Postscript',\n",
    " 'PT': 'Point',\n",
    " 'PTB': 'Please Text Back',\n",
    " 'PTO': 'Please Turn Over',\n",
    " 'QPSA': 'Que Pasa?',\n",
    " 'RATCHET': 'Rude',\n",
    " 'RBTL': 'Read Between The Lines',\n",
    " 'RLRT': 'Real Life Retweet',\n",
    " 'ROFL': 'Rolling On The Floor Laughing',\n",
    " 'ROFLOL': 'Rolling On The Floor Laughing Out Loud',\n",
    " 'ROTFLMAO': 'Rolling On The Floor Laughing My A.. Off',\n",
    " 'RT': 'Retweet',\n",
    " 'RUOK': 'Are You Ok',\n",
    " 'SFW': 'Safe For Work',\n",
    " 'SK8': 'Skate',\n",
    " 'SMH': 'Shake My Head',\n",
    " 'SQ': 'Square',\n",
    " 'SRSLY': 'Seriously',\n",
    " 'SSDD': 'Same Stuff Different Day',\n",
    " 'STATS': 'Your Sex And Age',\n",
    " 'TBH': 'To Be Honest',\n",
    " 'TBS': 'Tablespooful',\n",
    " 'TBSP': 'Tablespooful',\n",
    " 'TFW': 'That Feeling When',\n",
    " 'THKS': 'Thank You',\n",
    " 'THO': 'Though',\n",
    " 'THX': 'Thank You',\n",
    " 'TIA': 'Thanks In Advance',\n",
    " 'TIL': 'Today I Learned',\n",
    " 'TIME': 'Tears In My Eyes',\n",
    " 'TL;DR': 'Too Long I Did Not Read',\n",
    " 'TLDR': 'Too Long I Did Not Read',\n",
    " 'TMB': 'Tweet Me Back',\n",
    " 'TNTL': 'Trying Not To Laugh',\n",
    " 'TTFN': 'Ta-Ta For Now!',\n",
    " 'TTYL': 'Talk To You Later',\n",
    " 'U': 'You',\n",
    " 'U2': 'You Too',\n",
    " 'U4E': 'Yours For Ever',\n",
    " 'UTC': 'Coordinated Universal Time',\n",
    " 'W/': 'With',\n",
    " 'W/O': 'Without',\n",
    " 'W8': 'Wait...',\n",
    " 'WASSUP': 'What Is Up',\n",
    " 'WB': 'Welcome Back',\n",
    " 'WTF': 'What The F...',\n",
    " 'WTG': 'Way To Go!',\n",
    " 'WTPA': 'Where The Party At',\n",
    " 'WUF': 'Where Are You From?',\n",
    " 'WUZUP': 'What Is Up',\n",
    " 'WYWH': 'Wish You Were Here',\n",
    " 'YD': 'Yard',\n",
    " 'YGTR': 'You Got That Right',\n",
    " 'YNK': 'You Never Know',\n",
    " 'ZZZ': 'Sleeping, Bored, Tired',\n",
    " '€': ' Euro '}\n",
    "print('Total chat words listed:',len(chat_word_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T11:54:04.175288Z",
     "iopub.status.busy": "2023-11-13T11:54:04.174851Z",
     "iopub.status.idle": "2023-11-13T11:54:04.182517Z",
     "shell.execute_reply": "2023-11-13T11:54:04.181050Z",
     "shell.execute_reply.started": "2023-11-13T11:54:04.175252Z"
    }
   },
   "outputs": [],
   "source": [
    "# Defining function\n",
    "\n",
    "def chat_word_conversion(text):\n",
    "    new_text = []\n",
    "    for word in text.split():\n",
    "        if word.upper() in chat_word_dict:\n",
    "            new_text.append(chat_word_dict[word.upper()])\n",
    "        else:\n",
    "            new_text.append(word)\n",
    "    return ' '.join(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T11:54:06.436052Z",
     "iopub.status.busy": "2023-11-13T11:54:06.434684Z",
     "iopub.status.idle": "2023-11-13T11:54:06.442093Z",
     "shell.execute_reply": "2023-11-13T11:54:06.441193Z",
     "shell.execute_reply.started": "2023-11-13T11:54:06.436006Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'For Your Information I Love You Baby or Wife'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample5='fyi ILU babe'\n",
    "chat_word_conversion(sample5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying on dataset\n",
    "df['col_name'] = df['col_name'].apply(lambda x: chat_word_conversion(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **f. Spelling Correction**\n",
    "- Correct the spelling of words if needed to be done\n",
    "- To remove the complexity of model\n",
    "- Required when dealing with manually typed data/voice chat/audio text\n",
    "- We can use library like NLTK, spacy,TextBlob, PySpellChecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T05:11:57.419581Z",
     "iopub.status.busy": "2023-11-13T05:11:57.419057Z",
     "iopub.status.idle": "2023-11-13T05:11:57.427729Z",
     "shell.execute_reply": "2023-11-13T05:11:57.426413Z",
     "shell.execute_reply.started": "2023-11-13T05:11:57.419537Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ceertain conditions duriing sevaral ggeneration aree modified in the saame maner.'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample6='ceertain conditions duriing sevaral ggeneration aree modified in the saame maner.'\n",
    "sample6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T05:12:00.589916Z",
     "iopub.status.busy": "2023-11-13T05:12:00.589400Z",
     "iopub.status.idle": "2023-11-13T05:12:02.399215Z",
     "shell.execute_reply": "2023-11-13T05:12:02.398028Z",
     "shell.execute_reply.started": "2023-11-13T05:12:00.589877Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'certain conditions during several generation are modified in the same manner.'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing library\n",
    "from textblob import TextBlob\n",
    "\n",
    "txtblob = TextBlob(sample6)\n",
    "txtblob.correct().string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining function\n",
    "\n",
    "from textblob import TextBlob\n",
    "\n",
    "def spell_checker(text):\n",
    "    txtblob = TextBlob(text)\n",
    "    return txtblob.correct().string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying on dataset\n",
    "df['col_name'] = df['col_name'].apply(lambda x: spell_checker(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **g. Removing Stop Words**\n",
    "- Remove those words which doesn't creates any sense\n",
    "- We didn't remove stop words when we are going to do Parts of speech tagging\n",
    "- We can remove stop words using NLTK library\n",
    "- It will takes time to execute depending on the size of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T12:03:50.866851Z",
     "iopub.status.busy": "2023-11-13T12:03:50.865886Z",
     "iopub.status.idle": "2023-11-13T12:03:52.243731Z",
     "shell.execute_reply": "2023-11-13T12:03:52.242496Z",
     "shell.execute_reply.started": "2023-11-13T12:03:50.866810Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importing library\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "eng_stop_words = stopwords.words('english')\n",
    "# OR\n",
    "# sw_list = set(stopwords.words('english'))   # Convert the list to a set for faster membership tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T12:04:02.056197Z",
     "iopub.status.busy": "2023-11-13T12:04:02.054969Z",
     "iopub.status.idle": "2023-11-13T12:04:02.063435Z",
     "shell.execute_reply": "2023-11-13T12:04:02.062074Z",
     "shell.execute_reply.started": "2023-11-13T12:04:02.056150Z"
    }
   },
   "outputs": [],
   "source": [
    "# Defining function\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    new_text = []\n",
    "    for word in text.split():\n",
    "        if word.lower() in stopwords.words('english'):\n",
    "            new_text.append('')\n",
    "        else:\n",
    "            new_text.append(word)\n",
    "    x = new_text[:]\n",
    "    new_text.clear()\n",
    "    return ' '.join(x)\n",
    "\n",
    "# If above function not works\n",
    "def remove_stopwords(text):\n",
    "    if isinstance(text, str):\n",
    "        new_text = []\n",
    "        for word in text.split():\n",
    "            if word.lower() not in eng_stop_words:\n",
    "                new_text.append(word)\n",
    "        return ' '.join(new_text)\n",
    "    else:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T12:04:06.535383Z",
     "iopub.status.busy": "2023-11-13T12:04:06.534913Z",
     "iopub.status.idle": "2023-11-13T12:04:06.543533Z",
     "shell.execute_reply": "2023-11-13T12:04:06.542264Z",
     "shell.execute_reply.started": "2023-11-13T12:04:06.535346Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'basically theres a family where a little boy jake thinks theres a zombie in his closet  his parents are fighting all the timethis movie is slower than a soap opera and suddenly jake decides to become rambo and kill the zombieok first of all when youre going to make a film you must decide if its a thriller or a drama as a drama the movie is watchable parents are divorcing  arguing like in real life and then we have jake with his closet which totally ruins all the film i expected to see a boogeyman similar movie and instead i watched a drama with some meaningless thriller spots3 out of 10 just for the well playing parents  descent dialogs as for the shots with jake just ignore them'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample7 = df['review'][3]\n",
    "sample7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T12:04:10.525258Z",
     "iopub.status.busy": "2023-11-13T12:04:10.524834Z",
     "iopub.status.idle": "2023-11-13T12:04:10.554647Z",
     "shell.execute_reply": "2023-11-13T12:04:10.553443Z",
     "shell.execute_reply.started": "2023-11-13T12:04:10.525225Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'basically theres  family   little boy jake thinks theres  zombie   closet  parents  fighting   timethis movie  slower   soap opera  suddenly jake decides  become rambo  kill  zombieok first    youre going  make  film  must decide    thriller   drama   drama  movie  watchable parents  divorcing arguing like  real life     jake   closet  totally ruins   film  expected  see  boogeyman similar movie  instead  watched  drama   meaningless thriller spots3   10    well playing parents descent dialogs    shots  jake  ignore '"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_stopwords(sample7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying on dataset  ---> it might takes time\n",
    "df['review'] = df['review'].apply(lambda x: remove_stopwords(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T12:07:34.844529Z",
     "iopub.status.busy": "2023-11-13T12:07:34.843733Z",
     "iopub.status.idle": "2023-11-13T12:07:35.096227Z",
     "shell.execute_reply": "2023-11-13T12:07:35.095005Z",
     "shell.execute_reply.started": "2023-11-13T12:07:34.844487Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    one    reviewers  mentioned   watching  1 oz e...\n",
      "1     wonderful little production  filming techniqu...\n",
      "2     thought    wonderful way  spend time    hot s...\n",
      "3    basically theres  family   little boy jake thi...\n",
      "4    petter matteis love   time  money   visually s...\n",
      "5    probably  alltime favorite movie  story  selfl...\n",
      "6     sure would like  see  resurrection    dated s...\n",
      "7     show   amazing fresh innovative idea   70s   ...\n",
      "8    encouraged   positive comments   film     look...\n",
      "9      like original gut wrenching laughter   like ...\n",
      "Name: review, dtype: object\n",
      "1225.365400314331\n"
     ]
    }
   ],
   "source": [
    "# Time test on dataset\n",
    "start =time.time()\n",
    "\n",
    "x = df['review'].head(10).apply(lambda x: remove_stopwords(x))\n",
    "print(x)\n",
    "\n",
    "end=time.time()\n",
    "print((end-start)*5000) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **h. Handling Emojis**\n",
    "- Either remove the emoji from text\n",
    "- Or replace the emoji with its relevant meaning\n",
    "- Require when dealing with messaging app data or personal chats data\n",
    "- Do it before removing punctuation or special characters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T12:37:35.246940Z",
     "iopub.status.busy": "2023-11-13T12:37:35.245877Z",
     "iopub.status.idle": "2023-11-13T12:37:35.253231Z",
     "shell.execute_reply": "2023-11-13T12:37:35.252188Z",
     "shell.execute_reply.started": "2023-11-13T12:37:35.246894Z"
    }
   },
   "outputs": [],
   "source": [
    "# Defining function to remove emojis\n",
    "\n",
    "import emoji\n",
    "import re\n",
    "def remove_emojis(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F700-\\U0001F77F\"  # alchemical symbols\n",
    "                               u\"\\U0001F780-\\U0001F7FF\"  # Geometric Shapes Extended\n",
    "                               u\"\\U0001F800-\\U0001F8FF\"  # Supplemental Arrows-C\n",
    "                               u\"\\U0001F900-\\U0001F9FF\"  # Supplemental Symbols and Pictographs\n",
    "                               u\"\\U0001FA00-\\U0001FA6F\"  # Chess Symbols\n",
    "                               u\"\\U0001FA70-\\U0001FAFF\"  # Symbols and Pictographs Extended-A\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    results = emoji_pattern.sub('', text)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T12:37:43.917153Z",
     "iopub.status.busy": "2023-11-13T12:37:43.916338Z",
     "iopub.status.idle": "2023-11-13T12:37:43.922980Z",
     "shell.execute_reply": "2023-11-13T12:37:43.921492Z",
     "shell.execute_reply.started": "2023-11-13T12:37:43.917109Z"
    }
   },
   "outputs": [],
   "source": [
    "# Defining function to replace emojis with its relevant meaning\n",
    "\n",
    "import emoji\n",
    "def replace_emojis(text):\n",
    "    results = emoji.demojize(text)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T12:37:45.487635Z",
     "iopub.status.busy": "2023-11-13T12:37:45.487244Z",
     "iopub.status.idle": "2023-11-13T12:37:45.498437Z",
     "shell.execute_reply": "2023-11-13T12:37:45.497283Z",
     "shell.execute_reply.started": "2023-11-13T12:37:45.487605Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How are you doing? 😊👋🌟'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample8 = \"Hello! How are you doing? 😊👋🌟\"\n",
    "sample8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T12:38:27.012302Z",
     "iopub.status.busy": "2023-11-13T12:38:27.011139Z",
     "iopub.status.idle": "2023-11-13T12:38:27.018013Z",
     "shell.execute_reply": "2023-11-13T12:38:27.017106Z",
     "shell.execute_reply.started": "2023-11-13T12:38:27.012260Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How are you doing? \n",
      "Hello! How are you doing? :smiling_face_with_smiling_eyes::waving_hand::glowing_star:\n"
     ]
    }
   ],
   "source": [
    "print(remove_emojis(sample8))\n",
    "print(replace_emojis(sample8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **i. Tokenization**\n",
    "- Tokenization is basically breaking text documents into smaller parts\n",
    "- Smaller parts can be word, sentence or phases\n",
    "### Challenges\n",
    "- Prefix/Suffix/Infix ---> eg. $10, 10KM, ...-...\n",
    "- Exception ---> eg. Let's, U.S."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method-01: Using split function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T13:42:49.625184Z",
     "iopub.status.busy": "2023-11-13T13:42:49.624692Z",
     "iopub.status.idle": "2023-11-13T13:42:49.633781Z",
     "shell.execute_reply": "2023-11-13T13:42:49.632503Z",
     "shell.execute_reply.started": "2023-11-13T13:42:49.625146Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi', 'I', 'am', 'currently', 'learning', 'Natural', 'Language', 'Processing']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Word tokenization\n",
    "sent1 = \"Hi I am currently learning Natural Language Processing\"\n",
    "sent1.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T13:44:47.650595Z",
     "iopub.status.busy": "2023-11-13T13:44:47.649725Z",
     "iopub.status.idle": "2023-11-13T13:44:47.659153Z",
     "shell.execute_reply": "2023-11-13T13:44:47.657982Z",
     "shell.execute_reply.started": "2023-11-13T13:44:47.650550Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi I am currently learning Natural Language Processing',\n",
       " ' It is currently in market demand',\n",
       " ' If you wish you too can start learning']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sentence tokenization\n",
    "sent2 = \"Hi I am currently learning Natural Language Processing. It is currently in market demand. If you wish you too can start learning\"\n",
    "sent2.split('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T13:46:25.510208Z",
     "iopub.status.busy": "2023-11-13T13:46:25.509739Z",
     "iopub.status.idle": "2023-11-13T13:46:25.518481Z",
     "shell.execute_reply": "2023-11-13T13:46:25.517050Z",
     "shell.execute_reply.started": "2023-11-13T13:46:25.510167Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi!,', 'I', 'am', 'currently', 'learning', 'NLP!']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Problem with split function\n",
    "sent3 = \"Hi!, I'm currently learning NLP!\"\n",
    "sent3.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method-02: Using Regular Expression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T14:01:02.666988Z",
     "iopub.status.busy": "2023-11-13T14:01:02.666497Z",
     "iopub.status.idle": "2023-11-13T14:01:02.676354Z",
     "shell.execute_reply": "2023-11-13T14:01:02.674997Z",
     "shell.execute_reply.started": "2023-11-13T14:01:02.666936Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi',\n",
       " 'I',\n",
       " 'am',\n",
       " 'currently',\n",
       " 'learning',\n",
       " 'NLP',\n",
       " '.',\n",
       " \"It's\",\n",
       " 'currently',\n",
       " 'in',\n",
       " 'market',\n",
       " 'demand.',\n",
       " 'Would',\n",
       " 'you',\n",
       " 'like',\n",
       " 'to',\n",
       " 'learn',\n",
       " '.']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "sent4 = \"Hi!, I am currently learning NLP!. It's currently in market demand. Would you like to learn?.\"\n",
    "res4 = re.split(r'[!?,\\s]+', sent4)\n",
    "res4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method-03: NLTK Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T14:13:07.166414Z",
     "iopub.status.busy": "2023-11-13T14:13:07.165901Z",
     "iopub.status.idle": "2023-11-13T14:13:07.175081Z",
     "shell.execute_reply": "2023-11-13T14:13:07.173753Z",
     "shell.execute_reply.started": "2023-11-13T14:13:07.166374Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hi', '!', ',', 'I', 'am', 'currently', 'learning', 'NLP', '!', '.', 'It', \"'s\", 'currently', 'in', 'market', 'demand', '.', 'Would', 'you', 'like', 'to', 'learn', '?', '.']\n",
      "\n",
      "['Hi!, I am currently learning NLP!.', \"It's currently in market demand.\", 'Would you like to learn?.']\n"
     ]
    }
   ],
   "source": [
    "# Importing library\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "sample9 = \"Hi!, I am currently learning NLP!. It's currently in market demand. Would you like to learn?.\"\n",
    "print(word_tokenize(sample9))\n",
    "print()\n",
    "print(sent_tokenize(sample9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T14:14:04.341460Z",
     "iopub.status.busy": "2023-11-13T14:14:04.341019Z",
     "iopub.status.idle": "2023-11-13T14:14:04.350940Z",
     "shell.execute_reply": "2023-11-13T14:14:04.349524Z",
     "shell.execute_reply.started": "2023-11-13T14:14:04.341428Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'have', 'a', 'Ph.D', 'in', 'A.I', '.']\n",
      "\n",
      "['We', \"'re\", 'here', 'to', 'help', '!', 'you', 'can', 'mail', 'us', 'at', 'abc', '@', 'gmail.com']\n",
      "\n",
      "['This', 'face', 'cream', 'costs', '$', '5', 'in', 'U.S.A', '.']\n"
     ]
    }
   ],
   "source": [
    "# some more example ---> challenges for NLTK library\n",
    "s1='I have a Ph.D in A.I.'\n",
    "s2=\"We're here to help! you can mail us at abc@gmail.com\"\n",
    "s3='This face cream costs $5 in U.S.A.'\n",
    "s4=\"Hi!, I'm currently learning NLP!\"\n",
    "\n",
    "print(word_tokenize(s1))\n",
    "print()\n",
    "print(word_tokenize(s2))\n",
    "print()\n",
    "print(word_tokenize(s3))\n",
    "print()\n",
    "print(word_tokenize(s4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method-04: spaCy Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T14:23:33.092121Z",
     "iopub.status.busy": "2023-11-13T14:23:33.091113Z",
     "iopub.status.idle": "2023-11-13T14:23:40.268614Z",
     "shell.execute_reply": "2023-11-13T14:23:40.267238Z",
     "shell.execute_reply.started": "2023-11-13T14:23:33.092074Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importing library\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T14:24:02.551590Z",
     "iopub.status.busy": "2023-11-13T14:24:02.550853Z",
     "iopub.status.idle": "2023-11-13T14:24:02.557234Z",
     "shell.execute_reply": "2023-11-13T14:24:02.555966Z",
     "shell.execute_reply.started": "2023-11-13T14:24:02.551551Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let's try it\n",
    "s1='I have a Ph.D in A.I.'\n",
    "s2=\"We're here to help! you can mail us at abc@gmail.com\"\n",
    "s3='This face cream costs $5 in U.S.A.'\n",
    "s4=\"Hi!, I'm currently learning NLP!\"\n",
    "\n",
    "doc1 = nlp(s1)\n",
    "doc2 = nlp(s2)\n",
    "doc3 = nlp(s3)\n",
    "doc4 = nlp(s4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T14:32:18.091689Z",
     "iopub.status.busy": "2023-11-13T14:32:18.091208Z",
     "iopub.status.idle": "2023-11-13T14:32:18.099856Z",
     "shell.execute_reply": "2023-11-13T14:32:18.098633Z",
     "shell.execute_reply.started": "2023-11-13T14:32:18.091649Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I - have - a - Ph - . - D - in - A.I. - \n",
      "We - 're - here - to - help - ! - you - can - mail - us - at - abc@gmail.com - \n",
      "This - face - cream - costs - $ - 5 - in - U.S.A. - \n",
      "Hi - ! - , - I - 'm - currently - learning - NLP - ! - "
     ]
    }
   ],
   "source": [
    "for token in doc1:\n",
    "    print(token, end=' - ')\n",
    "print()\n",
    "for token in doc2:\n",
    "    print(token, end=' - ')\n",
    "print()\n",
    "for token in doc3:\n",
    "    print(token, end=' - ')\n",
    "print()\n",
    "for token in doc4:\n",
    "    print(token, end=' - ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### j. Stemming\n",
    "- In grammar, Inflection is the modification of a word to express different grammatical categories such as a tense, case, voice, aspect, person, number, gender, mood etc.\n",
    "- **Stemming is the process of reducing inflection in words to their root forms such as mapping a group of words to the same stem even if the stem itself is not a valid word in the language**\n",
    "- [eg. Write --> Write, Writes, Wrote, Written, Writing]\n",
    "- Most widely used in Information Retrieval system\n",
    "- Stemmer is an algorithm which is used to do stemming\n",
    "- Some stemmer in NLTK are PorterStemmer(english), SnowballStemmer(others)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T15:10:40.367316Z",
     "iopub.status.busy": "2023-11-13T15:10:40.366033Z",
     "iopub.status.idle": "2023-11-13T15:10:40.372506Z",
     "shell.execute_reply": "2023-11-13T15:10:40.371306Z",
     "shell.execute_reply.started": "2023-11-13T15:10:40.367272Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importing library\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T15:10:45.506365Z",
     "iopub.status.busy": "2023-11-13T15:10:45.505908Z",
     "iopub.status.idle": "2023-11-13T15:10:45.512281Z",
     "shell.execute_reply": "2023-11-13T15:10:45.511035Z",
     "shell.execute_reply.started": "2023-11-13T15:10:45.506326Z"
    }
   },
   "outputs": [],
   "source": [
    "# Defining function\n",
    "def stem_words(text):\n",
    "    return \" \".join([ps.stem(word) for word in text.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T15:30:46.927183Z",
     "iopub.status.busy": "2023-11-13T15:30:46.926720Z",
     "iopub.status.idle": "2023-11-13T15:30:46.934096Z",
     "shell.execute_reply": "2023-11-13T15:30:46.933229Z",
     "shell.execute_reply.started": "2023-11-13T15:30:46.927137Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Write Writes Wrote Written Writing walk walks walking walked'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s10 = 'Write Writes Wrote Written Writing walk walks walking walked'\n",
    "s10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T15:30:52.611138Z",
     "iopub.status.busy": "2023-11-13T15:30:52.610387Z",
     "iopub.status.idle": "2023-11-13T15:30:52.619429Z",
     "shell.execute_reply": "2023-11-13T15:30:52.618091Z",
     "shell.execute_reply.started": "2023-11-13T15:30:52.611099Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'write write wrote written write walk walk walk walk'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem_words(s10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T15:30:56.941774Z",
     "iopub.status.busy": "2023-11-13T15:30:56.940979Z",
     "iopub.status.idle": "2023-11-13T15:30:56.948868Z",
     "shell.execute_reply": "2023-11-13T15:30:56.947702Z",
     "shell.execute_reply.started": "2023-11-13T15:30:56.941731Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a wonderful little production the filming technique is very unassuming very oldtimebbc fashion and gives a comforting and sometimes discomforting sense of realism to the entire piece the actors are extremely well chosen michael sheen not only has got all the polari but he has all the voices down pat too you can truly see the seamless editing guided by the references to williams diary entries not only is it well worth the watching but it is a terrificly written and performed piece a masterful production about one of the great masters of comedy and his life the realism really comes home with the little things the fantasy of the guard which rather than use the traditional dream techniques remains solid then disappears it plays on our knowledge and our senses particularly with the scenes concerning orton and halliwell and the sets particularly of their flat with halliwells murals decorating every surface are terribly well done'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample10 = df['review'][1]\n",
    "sample10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T15:32:41.727083Z",
     "iopub.status.busy": "2023-11-13T15:32:41.726574Z",
     "iopub.status.idle": "2023-11-13T15:32:41.740803Z",
     "shell.execute_reply": "2023-11-13T15:32:41.739288Z",
     "shell.execute_reply.started": "2023-11-13T15:32:41.727044Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a wonder littl product the film techniqu is veri unassum veri oldtimebbc fashion and give a comfort and sometim discomfort sens of realism to the entir piec the actor are extrem well chosen michael sheen not onli ha got all the polari but he ha all the voic down pat too you can truli see the seamless edit guid by the refer to william diari entri not onli is it well worth the watch but it is a terrificli written and perform piec a master product about one of the great master of comedi and hi life the realism realli come home with the littl thing the fantasi of the guard which rather than use the tradit dream techniqu remain solid then disappear it play on our knowledg and our sens particularli with the scene concern orton and halliwel and the set particularli of their flat with halliwel mural decor everi surfac are terribl well done'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem_words(sample10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **k. Lemmatization**\n",
    "- In Lemmatization root word is lemma which is canonical form, dictionary form or citation form of set of words\n",
    "- Lemmatization in linguistics is the process of grouping together the inflected forms of a word so they can be analysed as a single item\n",
    "- It's used in computational linguistics, natural language processing (NLP) and chatbots.\n",
    "- Lemmatization is slower than Stemming\n",
    "- If we wants to show results to users then use Lemmatization else Stemming\n",
    "## **NOTE:**\n",
    "- Stemming is algorithm based so it is faster\n",
    "- Lemmatization is searching based that is why it is slow (it searches in Lexical dictionary in WordNet Lemmatizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T16:00:55.456609Z",
     "iopub.status.busy": "2023-11-13T16:00:55.456212Z",
     "iopub.status.idle": "2023-11-13T16:00:55.463989Z",
     "shell.execute_reply": "2023-11-13T16:00:55.462769Z",
     "shell.execute_reply.started": "2023-11-13T16:00:55.456577Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello!, I was reading and studying same time. Also I have a bad habit of bathing and running after taking breakfast or eating something.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample11 = 'Hello!, I was reading and studying same time. Also I have a bad habit of bathing and running after taking breakfast or eating something.'\n",
    "sample11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**----------------xxx----------------------CHECK BELOW---------------------xxx---------------------xxx**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T16:45:26.126024Z",
     "iopub.status.busy": "2023-11-13T16:45:26.125507Z",
     "iopub.status.idle": "2023-11-13T16:45:46.172317Z",
     "shell.execute_reply": "2023-11-13T16:45:46.170945Z",
     "shell.execute_reply.started": "2023-11-13T16:45:26.125980Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading wordnet: <urlopen error [WinError 10060] A\n",
      "[nltk_data]     connection attempt failed because the connected party\n",
      "[nltk_data]     did not properly respond after a period of time, or\n",
      "[nltk_data]     established connection failed because connected host\n",
      "[nltk_data]     has failed to respond>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing library\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('wordnet')                 # If not working\n",
    "# nltk.data.path.append('path_to_wordnet')   # Download and give path\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T16:01:30.936497Z",
     "iopub.status.busy": "2023-11-13T16:01:30.936046Z",
     "iopub.status.idle": "2023-11-13T16:01:30.947067Z",
     "shell.execute_reply": "2023-11-13T16:01:30.946210Z",
     "shell.execute_reply.started": "2023-11-13T16:01:30.936459Z"
    }
   },
   "outputs": [],
   "source": [
    "# Lets try this\n",
    "punc = '!,.?'\n",
    "sent_words = nltk.word_tokenize(sample11)\n",
    "for word in sent_words:\n",
    "    if word in punc:\n",
    "        sent_words.remove(word)\n",
    "sent_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{0:20}{1:20}\".format('Word','Lemma'))\n",
    "for word in sent_words:\n",
    "    print(\"{0:20}{1:20}\".format(word, lemmatizer.lemmatize(word, pos='v')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questions: \n",
    "Why and when we need to do tokenization, stemming and lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 134715,
     "sourceId": 320111,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30579,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
